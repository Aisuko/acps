{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd55a751",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T15:04:34.895766Z",
     "iopub.status.busy": "2025-06-27T15:04:34.895446Z",
     "iopub.status.idle": "2025-06-27T15:05:13.104311Z",
     "shell.execute_reply": "2025-06-27T15:05:13.103083Z"
    },
    "papermill": {
     "duration": 38.215388,
     "end_time": "2025-06-27T15:05:13.106185",
     "exception": false,
     "start_time": "2025-06-27T15:04:34.890797",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-27 15:04:56.960907: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1751036697.238845      14 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1751036697.323824      14 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Dict, Any\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "\n",
    "from doraemon import RawData\n",
    "\n",
    "class SoT:\n",
    "    \"\"\"\n",
    "    The code original from Sketch of Thought and I acknowlege them. I adapted the original code.\n",
    "    \n",
    "    Author: -\n",
    "    \n",
    "    \"\"\"\n",
    "    _device = None\n",
    "    _model_name = \"saytes/SoT_DistilBERT\"\n",
    "    _tokenizer = None\n",
    "    _model = None\n",
    "    _label_mapping = {\n",
    "        \"chunked_symbolism\": 0,\n",
    "        \"conceptual_chaining\": 1,\n",
    "        \"expert_lexicons\": 2\n",
    "    }\n",
    "    _context_cache = {\n",
    "       \"EN\": {\n",
    "          \"conceptual_chaining\": [\n",
    "             {\n",
    "                \"question\": \"What is the name of the currency used in Seoul?\",\n",
    "                \"answer\": \"<think>\\nLet’s think through this step by step\\n#Seoul → #South_Korea → Won\\n</think>\\n\\\\boxed{Korean Won}\"\n",
    "             },\n",
    "             {\n",
    "                \"question\": \"Which planet has the highest surface temperature?\\nChoices:\\nA) Mercury\\nB) Venus\\nC) Mars\\nD) Jupiter\",\n",
    "                \"answer\": \"<think>\\nLet’s think through this step by step\\n#heat_trap\\nMercury → no atmosphere → loses heat\\nVenus → thick CO2 → traps heat → hottest\\nMars → thin CO2 → cold\\nJupiter → no solid surface\\n</think>\\n\\\\boxed{B}\"\n",
    "             },\n",
    "             {\n",
    "                \"question\": \"Which vitamin is essential for blood clotting?\",\n",
    "                \"answer\": \"<think>\\nLet’s think through this step by step\\n#blood_clotting → #vitamin_K\\n</think>\\n\\\\boxed{Vitamin K}\"\n",
    "             }\n",
    "          ],\n",
    "          \"chunked_symbolism\": [\n",
    "             {\n",
    "                \"question\": \"A car accelerates at 2.5 m/s^2 for 10 seconds. If its initial velocity was 15 m/s, what is its final velocity?\",\n",
    "                \"answer\": \"<think>\\nLet’s think through this step by step\\na = 2.5 m/s^2\\nt = 10 s\\nvi = 15 m/s\\nvf = 15 + (2.5 × 10)\\nvf = 40 m/s\\n</think>\\n\\\\boxed{40}\"\n",
    "             },\n",
    "             {\n",
    "                \"question\": \"If a product costs $120 and there is a 15% discount, what is the final price?\\nChoices:\\nA) $10\\nB) $97\\nC) 102\",\n",
    "                \"answer\": \"<think>\\nLet’s think through this step by step\\nop = 120\\nd = 15%\\ndp = 120 × (15 / 100) = 18\\nfp = 120 - 18 = 102\\n</think>\\n\\\\boxed{C}\"\n",
    "             },\n",
    "             {\n",
    "                \"question\": \"Question: A circuit has a voltage of 12V and a resistance of 4Ω. What is the current?\",\n",
    "                \"answer\": \"<think>\\nLet’s think through this step by step\\nV = 12V\\nR = 4Ω\\nI = 12 / 4 = 3A\\n</think>\\n\\\\boxed{3}\"\n",
    "             }\n",
    "          ],\n",
    "          \"expert_lexicons\": [\n",
    "             {\n",
    "                \"question\": \"Context: The discovery of the first interstellar object passing through the Solar System, 1I/2017 U1 ('Oumuamua'), provoked intense and continuing interest from the scientific community and the general public.\\nQuestion: The interstellar object 1I/2017 U1 ('Oumuamua') exhibited unusual characteristics that led to various hypotheses about its origin. What does the designation \\\"1I/2017 U1\\\" signify?\\nChoices:\\nA) 1st Intergalactic object detected in 2017, classified under category U1\\nB) 1st Interstellar object cataloged, detected in 2017, following IAU naming conventions\\nC) 1st Independent Unclassified body observed beyond Neptune in 2017\",\n",
    "                \"answer\": \"<think>\\nLet’s think through this step by step\\n1I → 1st interstellar object\\n2017 → Year detected\\nU1 → Sequence ID\\nIAU → Naming rules\\n∴ 1st cataloged interstellar object (2017)\\n</think>\\n\\\\boxed{B}\"\n",
    "             },\n",
    "             {\n",
    "                \"question\": \"A patient with STEMI is given MONA therapy. They have a history of being allergic to aspirin. Are they at risk with this treatment?\",\n",
    "                \"answer\": \"<think>\\nLet’s think through this step by step\\nSTEMI → ST-Elevation MI\\nMONA → {Morphine, O2, Nitrates, Aspirin}\\n∴ Aspirin ∈ MONA\\n</think>\\n\\\\boxed{Yes}\"\n",
    "             },\n",
    "             {\n",
    "                \"question\": \"What does EBITDA measure?\",\n",
    "                \"answer\": \"<think>\\nLet’s think through this step by step\\nEBITDA → Earnings Before Interest, Taxes, Depreciation, Amortization\\n∴ Measures Core Profitability\\n</think>\\n\\\\boxed{Core Profitability}\"\n",
    "             }\n",
    "          ],\n",
    "          \"cot\": [\n",
    "             {\n",
    "                \"question\": \"Question: \\\"If a train travels 60 miles per hour for 3 hours, how far does it go?\\\"\",\n",
    "                \"answer\": \"<think>\\nLet’s think through this step by step\\n1. Speed = 60 mph, Time = 3 h\\n2. Distance = Speed × Time = 60 × 3 = 180 miles\\n</think>\\n\\\\boxed{180}\"\n",
    "             },\n",
    "             {\n",
    "                \"question\": \"Which planet has the highest surface temperature?\\nChoices:\\nA) Mercury\\nB) Venus\\nC) Mars\\nD) Jupiter\",\n",
    "                \"answer\": \"<think>\\nLet’s think through this step by step\\n1. Venus has thick CO2 atmosphere → strong greenhouse → highest surface temperature\\n</think>\\n\\\\boxed{B}\"\n",
    "             }\n",
    "          ]\n",
    "       }\n",
    "    }\n",
    "\n",
    "    EN_ChunkedSymbolism_SystemPrompt=\"\"\"\n",
    "    ## **Role & Objective**\n",
    "    You are a reasoning expert specializing in **Chunked Symbolism**, a cognitive reasoning technique that organizes numerical reasoning into structured steps. Your goal is to **utilize chunked symbolism** by representing information through **equations, variables, and step-by-step arithmetic**, while using minimal words.\n",
    "    \n",
    "    Chunked Symbolism is inspired by the cognitive science principle of **chunking**—the idea that humans process information more efficiently when grouped into meaningful units. Instead of solving problems in a free-form manner, **Chunked Symbolism breaks down complex operations into smaller, structured steps**.\n",
    "    \n",
    "    This method is particularly effective for:\n",
    "    - **Mathematical problems** (arithmetic, algebra, physics, engineering)\n",
    "    - **Symbolic reasoning** (logic-based computations, formula derivations)\n",
    "    - **Technical calculations** (financial modeling, physics simulations, unit conversions)\n",
    "    \n",
    "    ---\n",
    "    \n",
    "    ## **How to Apply Chunked Symbolism**\n",
    "    ### **Step-by-Step Guide**\n",
    "    1. **Identify Variables** – Extract relevant numerical values and define variables.\n",
    "    2. **Write Equations** – Represent the solution using **explicit mathematical formulas**.\n",
    "    3. **Perform Step-by-Step Computations** – Solve in **small, logical steps**, keeping each line clear.\n",
    "    4. **Label Units** – Maintain **consistent unit representation** to prevent ambiguity.\n",
    "    5. **Final Answer Formatting** – Present the answer in the **provided format** for clarity.\n",
    "    \n",
    "    ---\n",
    "    \n",
    "    ## **Rules & Directives**\n",
    "    1. **Use Equations & Variables**\n",
    "       - Define variables before computation.\n",
    "       - Always use **explicit equations** to represent reasoning.\n",
    "    \n",
    "    2. **Avoid Redundant Text**\n",
    "       - **Do not** restate the problem; go directly to calculations.\n",
    "       - Use **minimal context** only if it aids understanding.\n",
    "    \n",
    "    3. **Apply Step-by-Step Arithmetic**\n",
    "       - Break operations into **small, structured steps**.\n",
    "       - Ensure each line contains only **one computation** for clarity.\n",
    "    \n",
    "    4. **Output Format**\n",
    "       - Use the exact structured format:\n",
    "       ```\n",
    "       <think>\\nLet’s think through this step by step\\n\n",
    "       [shorthand reasoning]\n",
    "       </think>\n",
    "       \\boxed{[Final answer]}\n",
    "       ```\n",
    "       - The **final answer must be boxed**.\n",
    "       - **If the question is multiple-choice, return the correct letter option inside the box.**\n",
    "       - **Use minimal words in your response.**\n",
    "    \"\"\"\n",
    "    \n",
    "    EN_CoT_SystemPrompt=\"\"\"\n",
    "    You are an AI assistant trained to solve problems using explicit Chain of Thought (CoT) reasoning. Your goal is to break down problems into clear, logical steps and show your complete reasoning process before providing an answer.\n",
    "    \n",
    "    ### Output Format\n",
    "    All responses MUST use these exact tags:\n",
    "    \n",
    "    <think>\\nLet’s think through this step by step\\n\n",
    "    [Complete step-by-step reasoning using numbered steps]\n",
    "    </think>\n",
    "    \\boxed{[SINGLE Final Answer]}\n",
    "    \n",
    "    ### Guidelines\n",
    "    1. ALWAYS show your work inside the <think>\\nLet’s think through this step by step\\n tags\n",
    "    2. Break down complex problems into numbered steps\n",
    "    3. State your assumptions explicitly\n",
    "    4. Verify your answer makes sense in context\n",
    "    5. Use clear, everyday language to explain your reasoning\n",
    "    6. If multiple approaches are possible, explain why you chose yours\n",
    "    7. For word problems, begin by listing the given information\n",
    "    8. Include units in calculations where applicable\n",
    "    9. Put ONLY the final answer inside \\boxed{...}\n",
    "    10. Provide ONLY ONE final answer, DO NOT provide multiple options\n",
    "    \n",
    "    ### Key Principles\n",
    "    - Make your complete reasoning visible inside <think>\\nLet’s think through this step by step\\n tags\n",
    "    - Write as if explaining to someone who needs to understand each logical connection\n",
    "    - If you're unsure about something, state your assumptions clearly\n",
    "    - Check your answer against the original problem\n",
    "    - Keep the boxed answer concise and to the point\n",
    "    - Always maintain the exact format: <think>\\nLet’s think through this step by step\\n followed by \\boxed{...}\n",
    "    \n",
    "    ### Format Reminder\n",
    "    Provide only the final answer. For multiple-choice questions, your answer should be the corresponding letter or number. For other questions, your answer should be a single word or phrase only. **Do not add explanations or extra text to your answer.**\n",
    "    \n",
    "    Your response must ALWAYS follow this structure exactly:\n",
    "    \n",
    "    ```\n",
    "    <think>\\nLet’s think through this step by step\\n\n",
    "    1. [First step]\n",
    "    2. [Next step]\n",
    "    ...\n",
    "    n. [Final reasoning step]\n",
    "    </think>\n",
    "    \\boxed{[SINGLE Final Answer]}\n",
    "    ```\n",
    "    \"\"\"\n",
    "    \n",
    "    EN_ConceptualChaining_SystemPrompt=\"\"\"\n",
    "    ## **Role & Objective**  \n",
    "    You are a reasoning expert specializing in **structured concept linking** by connecting essential ideas in a logical sequence. Your goal is to **extract key terms** and present reasoning in **clear, stepwise chains** while minimizing unnecessary explanation.  \n",
    "    \n",
    "    This reasoning method follows a **conceptual chaining approach**, where information is **linked in structured steps** to establish relationships between ideas. This process integrates **associative recall (direct lookups)** and **multi-hop reasoning (sequential dependencies)** into a **unified framework**.  \n",
    "    \n",
    "    This method is most effective for:  \n",
    "    - **Commonsense reasoning** (quickly linking familiar ideas)  \n",
    "    - **Multi-hop inference** (tracing logical or causal dependencies)  \n",
    "    - **Fact-based recall** (retrieving knowledge with minimal cognitive load)  \n",
    "    \n",
    "    ---\n",
    "    \n",
    "    ## **How to Apply This Reasoning Method**  \n",
    "    1. **Extract Key Concepts** → Identify the most relevant words or entities.  \n",
    "    2. **Use Minimal Words** → Keep each reasoning step **concise and direct**.  \n",
    "    3. **Link Steps Sequentially** → Maintain a **clear and meaningful progression** between concepts.  \n",
    "    4. **Avoid Full Sentences** → Responses should use **structured keyword connections**.  \n",
    "    5. **Follow the Required Format** → Present answers using **stepwise chains for clarity**.  \n",
    "    \n",
    "    ---\n",
    "    \n",
    "    ## **Rules & Directives**\n",
    "    1. **Use Structured Concept Linking**\n",
    "       - Each step **must be logically connected**.\n",
    "       - Use arrows (`→`) to show dependencies.\n",
    "    \n",
    "    2. **Avoid Unnecessary Text**\n",
    "       - **Do not** restate the question.\n",
    "       - **Do not** use full sentences.\n",
    "    \n",
    "    3. **Maintain Logical Flow**\n",
    "       - Concepts must be **meaningfully ordered**.\n",
    "       - Ensure **each step contributes to the reasoning process**.\n",
    "    \n",
    "    4. **Output Format**\n",
    "       - Use the exact structured format:\n",
    "       ```\n",
    "       <think>\\nLet’s think through this step by step\\n\n",
    "       [shorthand reasoning]\n",
    "       </think>\n",
    "       \\boxed{[Final answer]}\n",
    "       ```\n",
    "       - The **final answer must be boxed**.\n",
    "       - **If the question is multiple-choice, return the correct letter option inside the box.**\n",
    "       - **If the questions is fact-based recall, return the True for or False inside the box.**\n",
    "       - **Use minimal words in your response.**\n",
    "    \"\"\"\n",
    "    \n",
    "    EN_ExpertLexicons_SystemPrompt=\"\"\"\n",
    "    ## **Role & Objective**  \n",
    "    You are a reasoning expert specializing in **Expert Lexicons**, a cognitive reasoning technique that **leverages domain-specific shorthand, technical symbols, and jargon** to ensure precise and efficient communication. Your goal is to **compress reasoning into high-information expressions** while maintaining **technical accuracy and clarity**.  \n",
    "    \n",
    "    Expert Lexicons is based on the principle that **domain experts communicate using shorthand and structured notation**. Instead of full explanations, this method **condenses reasoning into compact, high-density expressions** using technical symbols and field-specific abbreviations.\n",
    "    \n",
    "    This method is particularly effective for:  \n",
    "    - **Technical disciplines** (science, engineering, medicine, mathematics, and coding)  \n",
    "    - **Symbolic and formulaic reasoning** (using field-specific notation and logical expressions)  \n",
    "    - **Maximizing efficiency** (conveying information in the fewest possible tokens)\n",
    "    \n",
    "    ---\n",
    "    \n",
    "    ## **How to Apply Expert Lexicons**  \n",
    "    ### **Step-by-Step Guide**\n",
    "    1. **Use Technical Symbols** → Replace common terms with **mathematical, logical, or scientific notation** where applicable.  \n",
    "    2. **Leverage Abbreviations** → Use **domain-specific shorthand** to condense reasoning.  \n",
    "    3. **Prioritize Information Density** → Only include **essential reasoning elements**.  \n",
    "    4. **Follow Standardized Notation** → Adhere to **widely recognized conventions** within each field.  \n",
    "    5. **Maintain Structural Precision** → Ensure answers are formatted using **compact, industry-specific expressions**.  \n",
    "    \n",
    "    ---\n",
    "    \n",
    "    ## **Rules & Directives**  \n",
    "    1. **Use Domain-Specific Notation**  \n",
    "       - **Mathematical & Logical Reasoning** → `∑, ∴, ∝, Δ, →`  \n",
    "       - **Scientific Disciplines** → `mol, J, Hz, pH, Vmax`  \n",
    "       - **Medical & Engineering Fields** → `CHF, OOP, PID, μm, dB`  \n",
    "    \n",
    "    2. **Eliminate Redundant Text**  \n",
    "       - **No full sentences** – responses must be in **structured notation**.  \n",
    "       - **No restating the question** – directly express the solution.  \n",
    "    \n",
    "    3. **Keep Responses Ultra-Compact**  \n",
    "       - **Prioritize brevity** while maintaining **technical precision**.  \n",
    "       - Follow **industry standards** for notation and structured reasoning.  \n",
    "    \n",
    "    4. **Output Format**\n",
    "       - Use the exact structured format:\n",
    "       ```\n",
    "       <think>\\nLet’s think through this step by step\\n\n",
    "       [Shorthand reasoning using expert notation]\n",
    "       </think>\n",
    "       \\boxed{[Final answer]}\n",
    "       ```\n",
    "       - The **final answer must be boxed**.\n",
    "       - **If the question is multiple-choice, return the correct letter option inside the box.**\n",
    "       - **If the questions is fact-based recall, return the True for or False inside the box.**\n",
    "       - **Use minimal words in your response.**\n",
    "    \"\"\"\n",
    "\n",
    "    _prompts_en={\n",
    "        \"chunked_symbolism\":EN_ChunkedSymbolism_SystemPrompt,\n",
    "        \"cot\":EN_CoT_SystemPrompt,\n",
    "        \"conceptual_chaining\":EN_ConceptualChaining_SystemPrompt,\n",
    "        \"expert_lexicons\":EN_ExpertLexicons_SystemPrompt\n",
    "    }\n",
    "\n",
    "    _FEWER_SHORT_PROMPT_TEMPLATE: Dict[str, List[Dict[str, str]]] = {\n",
    "        \"FEVER\": [\n",
    "            {\n",
    "                'role': 'user',\n",
    "                'content': 'Poldark airs on HBO.\\nContext: Poldark is a British-American drama television series that was first broadcast on HBO One on 8 March 2015.'\n",
    "            },\n",
    "            {\n",
    "                'role': 'assistant',\n",
    "                'content': \"<think>\\nLet’s think through this step by step\\n#Poldark → #British-American drama → #HBO One → March 8, 2015\\n</think>\\n\\\\boxed{SUPPORTS}\"\n",
    "            },\n",
    "            {\n",
    "                'role': 'user',\n",
    "                'content': 'Homer Hickman did not write any historical fiction novels.\\nContext: Hickam has also written a number of best-selling novels including the \"Josh Thurlow\" but has stayed away from the historical fiction novels genre.'\n",
    "            },\n",
    "            {\n",
    "                'role': 'assistant',\n",
    "                'content': \"<think>\\nLet’s think through this step by step\\n#Homer Hickman → #Josh Thurlow → #Best-selling novels → No historical fiction genre\\n</think>\\n\\\\boxed{SUPPORTS}\"\n",
    "            },\n",
    "            {\n",
    "                'role': 'user',\n",
    "                'content': 'Colin Kaepernick is a poker player.\\nContext: Colin Rand Kaepernick -LRB- -LSB; ` kæpərnɪk -RSB- ; born November 3 , 1987 -RRB- is an American poker player.'\n",
    "            },\n",
    "            {\n",
    "                'role': 'assistant',\n",
    "                'content': \"<think>\\nLet’s think through this step by step\\n#Colin Kaepernick → #American poker player\\n</think>\\n\\\\boxed{SUPPORTS}\"\n",
    "            },\n",
    "            {\n",
    "                'role': 'user',\n",
    "                'content': 'Craig David is a pop music performer.\\nContext: Craig Ashley David -LRB- born 5 May 1981 -RRB- is a British country singer, songwriter, and record producer who rose to fame in 1999, featuring on the single, \"Re-Rewind\" by Artful Dodger.'\n",
    "            },\n",
    "            {\n",
    "                'role': 'assistant',\n",
    "                'content': \"<think>\\nLet’s think through this step by step\\n#Craig David → #Country singer → Not a pop performer\\n</think>\\n\\\\boxed{REFUTES}\"\n",
    "            }\n",
    "        ],\n",
    "        'HOTPOTQA': [\n",
    "            {\n",
    "                'role': 'user',\n",
    "                'content': \"Woman's Era and Naj are what kind of magazines?\\nContext: Woman's Era is a fortnightly women interest magazine published in English in India. Naj is a Polish language fortnightly lifestyle and women's magazine published in Warsaw, Poland.\"\n",
    "            },\n",
    "            {\n",
    "                'role': 'assistant',\n",
    "                'content': \"<think>\\nLet’s think through this step by step\\n#Woman's Era → fortnightly → women interest magazine\\n#Naj → Polish → fortnightly → lifestyle/women's magazine\\n</think>\\n\\\\boxed{fortnightly women interest magazine}\"\n",
    "            },\n",
    "            {\n",
    "                'role': 'user',\n",
    "                'content': \"The Rome Protocols were signed by three Prime Ministers one of which was assassinated as part of what?\\nContext: The Rome Protocols were a series of three international agreements signed in Rome on 17 March 1934 between the governments of Austria, Hungary and Italy. They were signed by Italian Prime Minister Benito Mussolini, Austrian Prime Minister Engelbert Dollfuss and Hungarian Prime Minister Gyula Gömbös. Engelbert Dollfuss (German: \\\"Engelbert Dollfuß\\\" , ] ; 4 October 1892 – 25 July 1934) was an Austrian Christian Social and Patriotic Front statesman. Dollfuss was assassinated as part of a failed coup attempt by Nazi agents in 1934.\"\n",
    "            },\n",
    "            {\n",
    "                'role': 'assistant',\n",
    "                'content': \"<think>\\nLet’s think through this step by step\\n#Rome Protocols → signed by Dollfuss\\n#Dollfuss → assassinated\\n#Assassinated as part of → failed coup attempt by Nazi agents\\n</think>\\n\\\\boxed{a failed coup attempt}\"\n",
    "            },\n",
    "            {\n",
    "                'role': 'user',\n",
    "                'content': \"Are Darren Benjamin Shepherd and Rémi Lange both American?\\nContext: Darren Benjamin Shepherd is an American screenwriter and film director. Rémi Lange (born 4 February 1969 in Gennevilliers, Hauts-de-Seine) is a French film director.\"\n",
    "            },\n",
    "            {\n",
    "                'role': 'assistant',\n",
    "                'content': \"<think>\\nLet’s think through this step by step\\n#Shepherd → American screenwriter/director\\n#Lange → French film director → Not American\\n</think>\\n\\\\boxed{no}\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "\n",
    "    @classmethod\n",
    "    def get_device(cls):\n",
    "        if cls._device is None:\n",
    "            cls._device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        return cls._device\n",
    "\n",
    "    @classmethod\n",
    "    def get_model_name(cls):\n",
    "        return cls._model_name\n",
    "\n",
    "    @classmethod\n",
    "    def get_tokenizer(cls):\n",
    "        if cls._tokenizer is None:\n",
    "            cls._tokenizer = DistilBertTokenizer.from_pretrained(cls.get_model_name())\n",
    "        return cls._tokenizer\n",
    "\n",
    "    @classmethod\n",
    "    def get_model(cls):\n",
    "        if cls._model is None:\n",
    "            cls._model = DistilBertForSequenceClassification.from_pretrained(\n",
    "                cls.get_model_name()\n",
    "            ).to(cls.get_device())\n",
    "        return cls._model\n",
    "\n",
    "    @classmethod\n",
    "    def get_label_mapping(cls):\n",
    "        return cls._label_mapping\n",
    "\n",
    "    @classmethod\n",
    "    def get_context_cache(cls):\n",
    "        return cls._context_cache\n",
    "\n",
    "    @classmethod\n",
    "    def get_prompts_en(cls):\n",
    "        return cls._prompts_en\n",
    "\n",
    "    @classmethod\n",
    "    def get_initialized_prompt(cls, paradigm: str, question: str = None,\n",
    "                               language_code: str = \"EN\",\n",
    "                               include_system_prompt: bool = True):\n",
    "        cache = cls.get_context_cache()[language_code][paradigm]\n",
    "        prompt = []\n",
    "        if include_system_prompt:\n",
    "            prompt.append({\n",
    "                \"role\": \"system\",\n",
    "                \"content\": cls.get_prompts_en()[paradigm]\n",
    "            })\n",
    "        for sp in cache:\n",
    "            prompt.append({\"role\": \"user\", \"content\": sp[\"question\"]})\n",
    "            prompt.append({\"role\": \"assistant\", \"content\": sp[\"answer\"]})\n",
    "        if question:\n",
    "            prompt.append({\"role\": \"user\", \"content\": question})\n",
    "        return prompt\n",
    "\n",
    "\n",
    "    @classmethod\n",
    "    def classify_question(cls, question: str) -> str:\n",
    "        tokenizer = cls.get_tokenizer()\n",
    "        model = cls.get_model()\n",
    "        inputs = tokenizer(\n",
    "            question, return_tensors=\"pt\", truncation=True, padding=True\n",
    "        ).to(cls.get_device())\n",
    "        logits = model(**inputs).logits\n",
    "        pred = torch.argmax(logits, dim=1).item()\n",
    "        rev_map = {v: k for k, v in cls.get_label_mapping().items()}\n",
    "        return rev_map[pred]\n",
    "\n",
    "\n",
    "    @classmethod\n",
    "    def few_short_support(cls, task_name: str, prompt: List[Dict[str, str]], few_short: List[Dict[str, str]], question: str=None) -> List[Dict[str, str]]:\n",
    "        \"\"\"\n",
    "        This method replaces the prompt list based on the task_name.\n",
    "        If task_name is 'FEVER', it replaces the user and assistant messages with the new few_short example.\n",
    "        Otherwise, it does nothing and returns the original prompt.\n",
    "\n",
    "        :param task_name: The name of the task.\n",
    "        :param prompt: The list of prompt entries (user and assistant messages).\n",
    "        :param few_short: The new few-shot example to replace the user and assistant messages in the prompt list.\n",
    "        :return: The updated prompt list.\n",
    "        \"\"\"\n",
    "        if task_name:\n",
    "            # Replace all user and assistant messages (except system role) with few_short\n",
    "            # Only the first role (system) will be retained\n",
    "            final_prompt = [prompt[0]] + few_short\n",
    "            if question:\n",
    "                final_prompt.append({\"role\": \"user\", \"content\": question})\n",
    "            return final_prompt\n",
    "        else:\n",
    "            # Do nothing and return the original prompt\n",
    "            return prompt\n",
    "\n",
    "\n",
    "    @classmethod\n",
    "    def get_few_short(cls, task_name: str) -> List[Dict[str, str]]:\n",
    "        \"\"\"\n",
    "        Returns the few-short prompt template for the given task name.\n",
    "        \n",
    "        :param task_name: The name of the task for which the few-short prompt is needed.\n",
    "        :return: The few-short prompt template for the task.\n",
    "        \"\"\"\n",
    "        # Retrieve the prompt template for the provided task_name, if it exists\n",
    "        if task_name in cls._FEWER_SHORT_PROMPT_TEMPLATE:\n",
    "            return cls._FEWER_SHORT_PROMPT_TEMPLATE[task_name]\n",
    "        else:\n",
    "            # Return an empty list if the task_name does not exist\n",
    "            return []\n",
    "\n",
    "\n",
    "    @classmethod\n",
    "    def build_prompt(cls, paradigm: str, query: str) -> List[Dict[str, str]]:\n",
    "        \"\"\"\n",
    "        Return the initialized prompt for the given paradigm and query.\n",
    "        \"\"\"\n",
    "        return cls.get_initialized_prompt(paradigm=paradigm, question=query)\n",
    "    \n",
    "    @classmethod\n",
    "    def expand_with_temperatures(cls, df: pd.DataFrame, temp_values: List[float], paradigm: str) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Duplicate each record in df for all given temperature values, attach corresponding prompts and t_p.\n",
    "        Returns expanded DataFrame.\n",
    "        \"\"\"\n",
    "        df = df.copy()\n",
    "        # Generate prompt for each row\n",
    "        df['prompt'] = df['query'].apply(lambda q: cls.build_prompt(paradigm=paradigm, query=q))\n",
    "        # Expand DataFrame for each temperature\n",
    "        df_exp = df.loc[df.index.repeat(len(temp_values))].reset_index(drop=True)\n",
    "        df_exp['t_p'] = temp_values * len(df)\n",
    "        return df_exp\n",
    "\n",
    "    @classmethod\n",
    "    def build_tasks(cls, df_exp: pd.DataFrame) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Convert expanded DataFrame to a list of model-valid dicts for RawData.\n",
    "        \"\"\"\n",
    "        return [RawData.model_validate(item).model_dump() for item in df_exp.to_dict(orient='records')]"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "sourceId": 247690240,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 46.038258,
   "end_time": "2025-06-27T15:05:16.137908",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-27T15:04:30.099650",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
